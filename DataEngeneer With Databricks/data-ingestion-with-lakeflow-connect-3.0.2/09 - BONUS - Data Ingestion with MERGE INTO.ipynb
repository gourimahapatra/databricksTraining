{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a5f72f5-9431-4bf1-b111-171061891ec0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82f2018c-d244-4f97-b826-8608a442ca76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 9 (BONUS) - Data Ingestion with MERGE INTO\n",
    "\n",
    "### You may not have time to complete this during class, so please review it afterward.\n",
    "\n",
    "MERGE INTO in Databricks is a powerful tool for data ingestion, especially for data ingestion. It enables efficient, atomic, scalable upsert and delete operations. This command is useful when you have an existing Delta table and you wish to combine incoming data. \n",
    "\n",
    "\n",
    "### Learning Objectives\n",
    "By the end of this lesson, you should be able to:\n",
    "- Utilize MERGE INTO to perform updates, inserts, and deletes on Delta tables.\n",
    "- Apply MERGE INTO with schema enforcement to manage data integrity.\n",
    "- Apply MERGE INTO with schema evolution to evolve the target tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d17262b-a441-4d44-97b8-eeb5190eef1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default and you have a Shared SQL warehouse.\n",
    "\n",
    "<!-- ![Select Cluster](./Includes/images/selecting_cluster_info.png) -->\n",
    "\n",
    "Follow these steps to select the classic compute cluster:\n",
    "\n",
    "\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "\n",
    "2. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "\n",
    "   - Click **More** in the drop-down.\n",
    "\n",
    "   - In the **Attach to an existing compute resource** window, use the first drop-down to select your unique cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "\n",
    "2. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "\n",
    "3. Wait a few minutes for the cluster to start.\n",
    "\n",
    "4. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d3c41cf-2bee-4c50-ae0f-94c7286bc8be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## A. Classroom Setup\n",
    "\n",
    "Run the following cell to configure your working environment for this notebook.\n",
    "\n",
    "**NOTE:** The `DA` object is only used in Databricks Academy courses and is not available outside of these courses. It will dynamically reference the information needed to run the course in the lab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d450c65-923a-40f6-bb8e-043c13b0cd7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Includes/Classroom-Setup-09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "620b58f9-6efb-4be3-8140-2f7b13b03be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Run the cell below to view your default catalog and schema. Notice that your default catalog is **dbacademy** and your default schema is your unique **labuser** schema.\n",
    "\n",
    "**NOTE:** The default catalog and schema are pre-configured for you to avoid the need to specify the three-level name when writing your tables (i.e., catalog.schema.table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "325e6575-fd71-4de8-8008-7a4338bac871",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT current_catalog(), current_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38c0daf7-6592-4809-87a2-82e6339b2785",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## B. Preview the Current Delta table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1640c52-78cc-4ae6-8d60-ddc9a40b11b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Preview the **main_users_target** table (the target table to update). \n",
    "\n",
    "    Notice that the table contains 4 rows of user information including their **id**, **first_name**, **email**, **sign_up_date**, and **status**. Each user's status is *current*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8c1d47e-12cd-4378-809d-e59aee736bec",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "View the main users table"
    }
   },
   "outputs": [],
   "source": [
    "SELECT * \n",
    "FROM main_users_target\n",
    "ORDER BY id;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f48b141a-a838-44cd-82c1-249dfcfa6d73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Preview the **update_users_source** table (the table to use to update the target). You can think of this as your incoming dataset that has arrived in cloud object storage. \n",
    "\n",
    "    Notice that the table contains 4 rows and the same columns. In the **status** column, it displays the action to take for each user. We want to:\n",
    "    - delete user **id** *1*\n",
    "    - update the email of user **id** *2*\n",
    "    - add new users with **id** values of *5* and *6*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a23f9dda-9ac9-4f9d-b8f6-0f72c8704d28",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "View the table that contains the updates"
    }
   },
   "outputs": [],
   "source": [
    "SELECT *\n",
    "FROM update_users_source\n",
    "ORDER BY id;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d75250a1-49d5-4113-a984-ade3f2d54ecd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## C. MERGE INTO\n",
    "\n",
    "As a part of ingestion, you can perform inserts, updates and deletes using data from a source table, view, or DataFrame into a target Delta table using the `MERGE` SQL operation. Delta Lake supports inserts, updates and deletes in `MERGE`, and supports extended syntax beyond the SQL standards to facilitate advanced use cases.\n",
    "<br></br>\n",
    "\n",
    "```\n",
    "MERGE INTO target t\n",
    "USING source s\n",
    "ON {merge_condition}\n",
    "WHEN MATCHED THEN {matched_action}\n",
    "WHEN NOT MATCHED THEN {not_matched_action}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df67e339-6b94-4a39-9a95-a9be7f517084",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### C1. Merge Target with the Incoming Data\n",
    "In this scenario we will want to update the current **main_users_target** table with user updates from the **update_users_source** table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b5ae3af-1e59-490f-b842-1e2d7f22aeed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Use the `MERGE INTO` statement to merge the **update_users_source** table into the **main_users_target** table based on the **id** column.\n",
    "\n",
    "    The code below does the following:\n",
    "    - The `MERGE INTO` specifies the target table **main_users_target** to be modified. The table referenced must be a Delta table.\n",
    "    - The `USING` statement specifies the source table **update_users_source** to be merged into the target table.\n",
    "    - The `ON` statement specifies the condition for merging. Here it will merge based on the matching **id** values.\n",
    "    - The `WHEN MATCHED AND source.status = 'update' THEN UPDATE SET` clause will update the target table's **email** and **status** if the condition is true.\n",
    "    - The `WHEN MATCHED AND source.status = 'delete' THEN DELETE` clause will delete the target table's row if true.\n",
    "    - The `WHEN NOT MATCHED THEN INSERT {cols} VALUES {columns to insert}` clause will insert new rows from the target table if there is not a match of the **id** column.\n",
    "\n",
    "    Run the statement and view the results. Notice that:\n",
    "    - the **num_affected_rows** is *4*\n",
    "    - the **num_updated_rows** is *1*\n",
    "    - the **num_deleted_rows** is *1*\n",
    "    - the **num_inserted_rows** is *2*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a8cddb2-c230-4f1c-be20-59fe9028c10c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Merge the updates into the main table"
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO main_users_target target\n",
    "USING update_users_source source\n",
    "ON target.id = source.id\n",
    "WHEN MATCHED AND source.status = 'update' THEN\n",
    "  UPDATE SET \n",
    "    target.email = source.email,\n",
    "    target.status = source.status\n",
    "WHEN MATCHED AND source.status = 'delete' THEN\n",
    "  DELETE\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT (id, first_name, email, sign_up_date, status)\n",
    "  VALUES (source.id, source.first_name, source.email, source.sign_up_date, source.status);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56325ce1-140b-4f2f-822f-7f30306de745",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. View the updated **main_users_target** table. Notice that:\n",
    "    - User **id** *1* was deleted.\n",
    "    - User **id** *2* has an updated email.\n",
    "    - User **id** *5* and *6* were added.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c9a6874-26e5-41ea-90eb-e0e489404915",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "View the updated table"
    }
   },
   "outputs": [],
   "source": [
    "SELECT *\n",
    "FROM main_users_target\n",
    "ORDER BY id;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8509b52-b458-46e0-840b-8b330fc6b516",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. Use the `DESCRIBE HISTORY` statement to view the history of the **main_users_target** table. Notice that there are now 4 versions of the table.\n",
    "    - Version *0* is the initial creation of the empty table.\n",
    "    - Version *1* is the insertion of values into the table.\n",
    "    - Version *2* is the merge (inserts, updates, deletes).\n",
    "    - Version *3* is the optimization that occurred on the Delta table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c2b5f3a-4eb1-40a1-9ee8-deceb80a817c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "View the history of the updated table"
    }
   },
   "outputs": [],
   "source": [
    "DESCRIBE HISTORY main_users_target;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00e89ab6-7182-4fd2-942d-e9fd2bb4b4be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4. You can use `VERSION AS OF` to query a specific version of the table. Query version *1* of the table to view the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4c346f7-b9e9-4b74-a0fb-07b578876b82",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Use time travel to view the original table"
    }
   },
   "outputs": [],
   "source": [
    "SELECT *\n",
    "FROM main_users_target VERSION AS OF 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "185ae989-e440-41cd-ad3d-9f2427caa10f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### C2. Schema Enforcement and Schema Evolution with MERGE INTO\n",
    "What if your source data evolves and adds new columns? You can use `MERGE WITH SCHEMA EVOLUTION` to update the schema of the target table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4790f14-f803-4369-9b45-0970bb0d7691",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. View the updated **main_users_target** table. Confirm that it contains *5* columns with the updated values from the previous `MERGE INTO`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46547f5e-4f77-4010-8267-24cd365c05c1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "View the current version of the table"
    }
   },
   "outputs": [],
   "source": [
    "SELECT *\n",
    "FROM main_users_target\n",
    "ORDER BY ID;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f631d3f-e309-45ca-b438-99eaa3cc715a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. View the **new_users_source** table. This table contains an additional column named **country**, which captures information about our new users. This column was not captured with the original data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "229ab1cd-e705-4cad-91a8-d1797bfc8aad",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "View the new data to merge into the main table"
    }
   },
   "outputs": [],
   "source": [
    "SELECT *\n",
    "FROM new_users_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85f44cec-aaa7-4f89-bb6c-98aeb7c2d9e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. Use the `MERGE INTO` statement to update the target table **main_users_target** with the **new_users_source** table.\n",
    "\n",
    "    The only change in this `MERGE INTO` statement is in the last `WHEN NOT MATCHED AND source.status='new' THEN` clause. Here, we added the **country** column to insert into the target table.\n",
    "\n",
    "    Run the query and view the error:\n",
    "\n",
    "    *Cannot resolve country in INSERT clause given columns target.id, target.first_name, target.email, target.sign_up_date, target.status.*\n",
    "\n",
    "    Notice that the statement cannot resolve the **country** column in the INSERT clause.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2511f9e2-b676-41ee-b37c-9a1184b2b4b5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Try to merge a table with an additional column (ERROR)"
    }
   },
   "outputs": [],
   "source": [
    "--------------------------------------------\n",
    "-- This query will return an ERROR\n",
    "--------------------------------------------\n",
    "\n",
    "MERGE INTO main_users_target target\n",
    "USING new_users_source source\n",
    "ON target.id = source.id\n",
    "WHEN MATCHED AND source.status = 'update' THEN\n",
    "  UPDATE SET \n",
    "    target.email = source.email,\n",
    "    target.status = source.status\n",
    "WHEN MATCHED AND source.status = 'delete' THEN\n",
    "  DELETE\n",
    "WHEN NOT MATCHED AND source.status = 'new' THEN\n",
    "  INSERT (id, first_name, email, sign_up_date, status, country)\n",
    "  VALUES (source.id, source.first_name, source.email, source.sign_up_date, source.status, source.country);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42d8a329-2858-4ef2-a535-c0f60f5ca716",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4. You must explicitly enable schema evolution to evolve the schema of the target table. In Databricks Runtime 15.2 and above, you can specify schema evolution in a merge statement using SQL with `MERGE WITH SCHEMA EVOLUTION INTO` statement. \n",
    "\n",
    "    [Schema evolution syntax for merge](https://docs.databricks.com/en/delta/update-schema.html#schema-evolution-syntax-for-merge)\n",
    "\n",
    "**NOTES**: You can also set the Spark conf `spark.databricks.delta.schema.autoMerge.enabled` to *true* for the current SparkSession. For more information check out the [Enable schema evolution](https://docs.databricks.com/en/delta/update-schema.html#enable-schema-evolution) documentation page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2dd2f0a5-20cc-494b-8de4-d7d2b66e93e7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Use MERGE INTO with schema evolution"
    }
   },
   "outputs": [],
   "source": [
    "MERGE WITH SCHEMA EVOLUTION INTO main_users_target target  -- Use the MERGE WITH SCHEMA EVOLUTION INTO statement\n",
    "USING new_users_source source\n",
    "ON target.id = source.id\n",
    "WHEN MATCHED AND source.status = 'update' THEN\n",
    "  UPDATE SET \n",
    "    target.email = source.email,\n",
    "    target.status = source.status\n",
    "WHEN MATCHED AND source.status = 'delete' THEN\n",
    "  DELETE\n",
    "WHEN NOT MATCHED AND source.status = 'new' THEN\n",
    "  INSERT (id, first_name, email, sign_up_date, status, country)\n",
    "  VALUES (source.id, source.first_name, source.email, source.sign_up_date, source.status, source.country);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb5f0f35-7969-4e6a-a25d-cdda49667f73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "5. Preview the **main_users_target** table. Notice the following:\n",
    "    - The **country** column was added to the table, evolving the table schema.\n",
    "    - The three new users were inserted into the table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6244e684-ad42-4f66-842f-90ac448a4813",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "View the updated table with the new column 'country'"
    }
   },
   "outputs": [],
   "source": [
    "SELECT * \n",
    "FROM main_users_target;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c8e3751-c411-4bf2-a9c1-1ac9faabbfc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "6. View the history of the **main_users_target** table. Notice there is now a version *_4_* reflecting the latest merge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e3133dc-926e-4577-8e0f-550b60cc5f99",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "View the history of the main table"
    }
   },
   "outputs": [],
   "source": [
    "DESCRIBE HISTORY main_users_target;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e74c968f-1c08-4479-a72f-c93a6e107922",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "&copy; 2025 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"blank\">Apache Software Foundation</a>.<br/>\n",
    "<br/><a href=\"https://databricks.com/privacy-policy\" target=\"blank\">Privacy Policy</a> | \n",
    "<a href=\"https://databricks.com/terms-of-use\" target=\"blank\">Terms of Use</a> | \n",
    "<a href=\"https://help.databricks.com/\" target=\"blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {},
   "notebookName": "09 - BONUS - Data Ingestion with MERGE INTO",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}